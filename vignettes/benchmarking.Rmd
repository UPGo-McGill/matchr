---
title: "Parallel processing and performance benchmarking"
author: "David Wachsmuth"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parallel processing and performance benchmarking}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(matchr)
```

The functions in matchr can be very computation- and time-intensive. While with small or medium-sized datasets they can be used "out of the box" with no considerations for optimizing performance, processing large sets of images will potentially be frustratingly slow without some care to leveraging multicore processors and to memory requirements.

The key takeaways are:

- Enable parallel processing with the {future} package, most simply by setting `future::plan(multisession)`.
- By default, matchr functions only enable parallel processing where empirical testing suggests that this will improve performance, but parallel processing can be forced by setting the global option `options(matchr.force_parallel = TRUE)`.

The following discussion will rely on examples taken from two large sets of images. The `paths_low` vector contains low-resolution images (roughly 200 x 150 pixels, and 8 kB), while the `paths_high` vector contains higher-resolution images (between 640 x 480 and 1200 x 800, and 170 kB). To reproduce the benchmarks and analysis in this vignette, point the following lines at a pair of folders with low- and high- resolution images, respectively.

```
paths_low <- list.files("example_low", full.names = TRUE)
paths_high <- list.files("example_high", full.names = TRUE)
```

## Parallel processing

All of the time-consuming functions in matchr support parallel and remote processing via the [future](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) package. If a multisession, multicore, or cluster plan is set through future, matchr functions will generally perform substantially faster. For local workloads (i.e. workloads not being executed on a remote computing cluster), the most straightforward way to leverage parallel processing will be to run the following two lines before executing matchr functions:

```
library(future)
plan(multisession)
```

This will initiate a set of background processes which will share the computational workload of matchr functions. By default, one process will be initiated for each (real or virtual) CPU core on the local computer.

While in theory running a function using four cores instead of a single core might be expected to quadruple its execution speed, in practice the gains from parallel processing are usually much less than this, because of communication overhead between the main process and the background processes. In particular, if large data objects need to be passed between processes, the time this takes can swamp the gains from splitting calculations across processes. The functions in matchr send the minimum possible amount of data between processes—for example, paths to images on disk rather than the image data itself—but even so it is often true that for quick tasks a non-parallelized approach will be faster.

By default, regardless of the plan which has been set with `future::plan`, matchr will only enable parallel processing in scenarios where testing has indicated that this will reduce computation time. For example, in `load_image` and `create_signature`, parallel processing is turned off by default when reading images smaller than 100kB off a local drive. To override this default, set the `matchr.force_parallel` option to TRUE (with `options(matchr.force_parallel = TRUE)`) for a temporary override, or add the line `MATCHR_FORCE_PARALLEL = TRUE` to the .Renviron file for a permanent override.

In order to explore the impacts of parallel processing on computation time, the following benchmarks enable the `force_parallel` option.

```
options(matchr.force_parallel = TRUE)
```

### load_image

We begin with timings for reading vectors of 100, 1000 and 10,000 file paths with `load_image`. Because the memory requirements of importing the higher-resolution images are so high, only 1000 images are read in that case.

```{r li_timing, eval = FALSE}
library(future)
library(dplyr)
library(tidyr)
library(ggplot2)

li_bench <- 
  bench::press(
    length = c(100, 1000, 10000),
    workers = c(1, 2, 4, 8, 16, 32), {
      if (workers == 1) plan(sequential) else plan(multisession, workers = workers)
      bench::mark(
        low = load_image(paths_low[1:length], quiet = TRUE),
        high = if (length <= 1000) load_image(paths_high[1:length], quiet = TRUE),
        iterations = 20, check = FALSE)
      })

li_bench %>% 
  filter(expression == "low" | length < 10000) %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(expression), nrow = 2, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

``` {r li_timing_graph, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 6}
library(bench)
library(dplyr)
library(tidyr)
library(ggplot2)

load(here::here("inst", "li_bench.Rdata"))

li_bench %>% 
  filter(expression == "low" | length < 10000) %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(expression), nrow = 2, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

The figure shows the relationship between the number of parallel threads ("workers"), the size and length of the input vector, and the computational time of the load_image function. While in some specific cases the parallel workloads finished slightly faster than the sequential versions, in general there is no benefit to running `load_image` in parallel. For this reason, load_image by default will operate sequentially unless parallel processing is forced with the option `matchr.force_parallel`.

### create_signature

Because the memory requirements of reading many images into memory at once are so high (see [Memory requirements](#memory) below), it is rarely feasible to use `load_image` directly on a large set of images. Instead, `create_signature` combines the (memory-intensive) step of importing images with the (less memory-intensive) step of calculating signatures based on the colours and shades present in each image, and proceeds one image at a time. Each parallel process reads one image into memory, calculates the image signature, and discards the image from memory, before moving on to the next image. This makes it possible to process arbitrarily large sets of images with `create_signature`, and increases the usefulness of parallel processing.

```{r cs_timing, eval = FALSE}
cs_bench <- 
  bench::press(
    length = c(1000, 10000),
    workers = c(1, 2, 4, 8, 16, 32), {
      if (workers == 1) plan(sequential) else plan(multisession, workers = workers)
      bench::mark(
        low = create_signature(paths_low[1:length], backup = FALSE, quiet = TRUE),
        high = create_signature(paths_high[1:length], backup = FALSE, quiet = TRUE),
        iterations = 20, check = FALSE)
      })

cs_bench %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(expression), nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

``` {r cs_timing_graph, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 6}

load(here::here("inst", "cs_bench.Rdata"))

cs_bench %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(expression), nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

The results demonstrate, first of all, that the completion time of `create_signature` scales roughly linearly with the number of images being read. The non-parallel (`workers == 1`) version of the function reads 1,000 low-resolution images in 6.4 seconds, and 10,000 images in 41.2 seconds. It reads 1,000 higher-resolution images in 1.6 minutes and 10,000 in 16.5 minutes.

Secondly, parallel versions of `create_signature` produce dramatic speed increases, particularly when reading higher-resolution images. For low core counts, the increases are nearly linear: two workers process the 1,000 and 10,000 higher-resolution images 2.0 and 2.1 times faster than a single worker, four workers are 3.7 and 4.0 times faster, and eight workers are 7.1 and 7.7 times faster. For large workloads (e.g. 100,000 images or more), this can translate into `create_signature` finishing in minutes instead of hours. The same dynamics are present with low-resolution images, although with slightly smaller speed gains (e.g. eight workers process the 1,000 and 10,000 lower-resolution images 4.6 and 3.7 times faster than a single worker, respectively). While the marginal performance improvements to adding more workers decline at higher core counts, there is no point within the testing parameters at which adding more workers reduces performance. For this reason, by default `create_signature` always uses the maximum number of available cores when it is processing raw file paths. (By contrast, when `create_signature` operates on images which have already been loaded into memory with `load_image`, the communication overhead introduced by passing the data to each worker consistently swamps the performance gains from parallel processing, so parallel processing is never enabled in these cases.)


### match_signatures

The core functionality of `match_signatures` is to calculate correlations between the image signatures in a pair of `matchr_signature` vectors. Because each signature in the left-hand vector needs to be compared to each signature in the right-hand vector, the computational requirements increase quadratically with vector size. (E.g. comparing two 100-length vectors implies 100 ^ 2 = 10,000 calculations, while comparing two 200-length vectors implies 200 ^ 2 = 40,000 calculations.)

The `match_signatures` function includes an argument `compare_aspect_ratios`, which uses k-means clustering to split the input image signatures into groups with similar aspect ratios. This has two important implications. First, assuming the image sets being compared don't feature any extremely distorted scaling (e.g. landscape pictures stretched into portrait orientation), splitting by aspect ratio will tend to reduce the possibility for false positive matches, since, e.g., portrait and landscape images will not be compared to each other. Second, using `compare_aspect_ratios` can significantly shrink the number of image comparisons which need to be made, and thus speed up computation time. As a simple example, two sets of 100 images require 100 ^ 2 = 10,000 calculations to be compared, but if each set is split into 50 portrait and 50 landscape images, only 50 ^ 2 * 2 = 5,000 calculations will be needed. The function evaluates a range of different 

```{r ms_timing, eval = FALSE}
ms_bench <- 
  bench::press(
    length = c(1000, 10000),
    workers = c(1, 2, 4, 8, 16, 32),
    compare = c(TRUE, FALSE), {
      if (workers == 1) plan(sequential) else plan(multisession, workers = workers)
      bench::mark(ms = match_signatures(sig_high[1:length], sig_low[1:length], 
                                        compare_aspect_ratios = compare, 
                                        backup = FALSE, quiet = TRUE),
                  iterations = 20, check = FALSE)
    })

ms_bench %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(compare), nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

``` {r ms_timing_graph, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 6}

load(here::here("inst", "ms_bench.Rdata"))

ms_bench %>% 
  unnest(c(time, gc)) %>% 
  ggplot() +
  geom_boxplot(aes(time, as.factor(length), colour = as.factor(workers))) +
  scale_colour_viridis_d(name = "workers") +
  bench:::scale_x_bench_time() +
  facet_wrap(vars(compare), nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


## Memory requirements {#memory}

``` {r li_memory, eval = FALSE}

li_bench %>%
  filter(plan == "seq") %>% 
  group_by(image_vector) %>% 
  summarize(mem_alloc = first(mem_alloc)) %>% 
  separate(image_vector, into = c("img_res", "length"), sep = "_") %>% 
  mutate(length = case_when(length == "100" ~ 100,
                            length == "1k" ~ 1000,
                            length == "10k" ~ 10000)) %>% 
  ggplot(aes(x = length, y = mem_alloc, colour = img_res)) +
  geom_line(lwd = 2) +
  scale_x_log10(labels = scales::comma) +
  scale_y_log10(labels = scales::comma_format(accuracy = 1, scale = 1/(1000 ^ 3),
                                              suffix = " GB")) +
  scale_colour_viridis_d() +
  theme_minimal() +
  theme(legend.position = "bottom")

```


## Progress reporting

All time-consuming matchr functions support progress reporting via the [progressr](https://cran.r-project.org/web/packages/progressr/vignettes/progressr-intro.html) package. To enable progress reporting, simply run the following line of code before running matchr functions:

```
progressr::handlers(global = TRUE)
```

Progress reporting carries a small performance overhead, and while matchr scales the amount of progress reports adaptively to the size of the workload, matchr functions will run slightly faster if progress reporting is disabled. To disable progress reporting on a per-function basis, set the argument `quiet = TRUE`, which is available in every matchr function which supports progress reporting.
