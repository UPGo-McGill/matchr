---
title: "An introduction to matchr"
author: "David Wachsmuth"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{An introduction to matchr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The goal of matchr is to facilitate fast and reliable comparison of large sets of images to identify identical or nearly-identical pairs. It works by generating distinctive image signatures from pixel data then correlating these signatures between sets of images. matchr's approach allows for image comparisons to be made on large sets of images (tens or hundreds of thousands of files) on even modest computer hardware. This introductory vignette demonstrates the standard matchr workflow, from importing images and generating signatures to identifying and refining matches.

```{r setup, include = FALSE}
library(matchr)
```

```
library(matchr)
```

## How matchr's image matching works

If two image files are identical at the byte level, comparing them is trivial. The motivation for matchr's development, by contrast, was the need to compare images hosted by web services that compress and resize uploads differently. In other words, when the same exact file is uploaded to two services, the resulting files may be visually identical but completely different byte-to-byte. In addition, the same underlying image may be modified in slightly different ways before being uploaded to different services (e.g. with a small text overlay, or with a change to tint or contrast). A human could identify the images as the same, but again the byte-level data will be different. matchr is designed to solve these problems at large scale and efficiently, so that hundreds of thousands of images can be compared even on a laptop with minimal CPU power and RAM.

The strategy matchr uses is to extract relatively small but expressive "signatures" from each image, and compare these signatures mathematically. These signatures are "perceptual hashes" generated with the {OpenImageR} package. The perceptual hashing implementation used here downsamples images into 8x8 greyscale bitmaps, and then applies a discrete cosine transformation to each pixel and identifies pixels which are above or below the overall mean. matchr performs this operation twice (in slightly different ways) for each image, and uses the resulting 128-bit binary number as an image signature. This signature can identify a given image even if the image is rescaled, compressed or has a small overlay added to it, and thus serves as a reliable indicator of whether two images are the same.

Once image signatures have been generated for a set of images, matchr uses matrix algebra to compare each signature against each other signature using Hamming distances to identify potential matches. The Hamming distance measures the number of characters or bits of two strings or binary numbers which are different from each other. For matchr, the lower the Hamming distance, the closer the image signatures are to being identical, and thus the higher the likelihood that the underlying images are the same.

matchr has two comparison modes. If you supply a single set of images to its functions, matchr will identify all potential pairwise matches within that set. E.g., for a input vector `x`, it may determine that `x[1]` and `x[4]` are potential matches, along with `x[2]` and `x[3]`. If you supply two sets of images, by contrast, matchr will identify all potential pairwise matches *between* the two sets. E.g., for input vectors `x` and `y`, it may identify `x[1]` and `y[2]` as matches, but it will *not* identify `x[1]` and `x[4]`.

Since some true matches will inevitably have lower Hamming distances than some non-matches (because, e.g., the same image was de-saturated then compressed in one image set and left untouched in the other set), there is no possible "magic" threshold which is guaranteed to identify all true positives and exclude all true negatives. The parameters matchr uses to identify potential matches can be modified at will, but the defaults are tuned to produce very few false negatives, at the cost of producing somewhat more false positives. In other words, the default use case is based on the assumption that nearly every single match needs to be identified. For this reason, matchr provides an interactive Shiny app which can be used to manually verify the results of the automated matching process. The [performance vignette](performance.html) discusses the image matching parameters in greater detail, and provides sensible defaults for different use cases.

## Quick start

The simplest way to compare image sets with matchr is to use `match_images`, which is a convenience wrapper around the main functions in a standard matchr workflow. It does not allow much customization of parameters and doesn't scale well to extremely large image sets, but is a good choice when you just want to quickly identify duplicate images.

Here we demonstrate `match_images` being run on a single vector of internet images, using the `example_urls` data object included in matchr:

```{r paths}
example_urls
```

```{r modify_urls_and_make_custom_functions, echo = FALSE}
# This is necessary to allow the vignette to build offline and still give proper
# error messages

# Start by replacing example_urls with links to local resources
display_urls <- example_urls
example_urls <- list.files(here::here("tests", "testthat", "resources"), 
                           full.names = TRUE)
example_urls <- example_urls[c(3, 1:2, 5:6, 8, 7, 10, 9, 12, 11, 13, 16:17, 4)]

# Next overwrite match_images and load_images to give a different warning
match_images <- function(...) {
  tryCatch(matchr::match_images(...), warning = function(w) {
    warning(paste0("Input 'https://upgo.lab.mcgill.ca/resources/img_2_",
                   "corrupt.jpg' is invalid; output is NA."), call. = FALSE)
    suppressWarnings(matchr::match_images(...))
  }) 
}

load_image <- function(...) {
  tryCatch(matchr::load_image(...), warning = function(w) {
    warning(paste0("Input 'https://upgo.lab.mcgill.ca/resources/img_2_",
                   "corrupt.jpg' is invalid; output is NA."), call. = FALSE)
    suppressWarnings(matchr::load_image(...))
  }) 
}

```

`match_images` takes a `compare` argument, which controls whether the interactive `compare_images` Shiny app should be run to manually verify match results. This can only be run in an interactive session, so for the vignette `compare` is set to `FALSE`.

```{r match_images}
all_matches <- match_images(example_urls, compare = FALSE)
```

The results are returned as a data frame in which each row is a pairwise match between two of the input images. The function also generated a warning that one of the imported images was invalid. ("img_2_corrupt.jpg" is a purposely corrupted image, included in the test set to demonstrate what happens when matchr encounters an image it can't read.) 

```{r match_images_edit, echo = FALSE}
all_matches$x_path <- display_urls[c(10, 1, 1, 2, 6, 8)]
all_matches$y_path <- display_urls[c(11, 2, 3, 3, 7, 9)]
```

```{r match_images_display}
all_matches
```

The data frame has six rows, which correspond to six matches among the fifteen images in `test_urls`. The "x_path" and "y_path" fields show the file paths or URLs of the images which were matched. The next two fields ("x_sig" and "y_sig") contain the `matchr_signature` image signature vectors for the images which were matched. These vectors contain the image signatures used for matching, alongside other metadata from the images such as resolution, colour channels, and file path. The final field ("distance") gives a modified version of the Hamming distance between the image signatures of the two matching images, with lower values meaning the two images are more likely to be the same. If `match_images` is run with its default `compare = TRUE` setting, using the interactive image comparison Shiny app to manually confirm the results of the matching process will add `match` and `highlight` fields to the output data frame, which respectively identify image pairs whose status ("match" or "no match") was visually confirmed and image pairs flagged for further follow up.

Image comparison in matchr (either in `match_images` or the component functions) can identify matches within a single image set (as demonstrated above) or can identify matches between two image sets. This latter mode simply requires passing two input vectors to the functions:

```{r match_images_xy}
match_images(example_urls[1:7], example_urls[8:15], compare = FALSE)
```

In this case no matches were found, so the output data frame is empty.

Because `match_images` provides a streamlined wrapper around the entire matchr workflow, it is convenient for quickly identifying matches from small image sets, but it does not scale well to more complicated image matching tasks. The remainder of this vignette provides a step-by-step guide to the functions which `match_images` calls internally, and which will generally be used directly on image sets in real-world tasks. The standard matchr workflow generally looks like this:

- Use `load_images` on a vector of file paths or URLs to read image files into memory as a `matchr_image` vector. (This step is only feasible for small image sets.)
- Use `create_signatures` on a `matchr_image` vector (or more likely a vector of file paths for large image sets) to generate a `matchr_signature` vector containing distinctive image signatures.
- Use `match_signatures` on one or two `matchr_signature` vectors to generate a `matchr_matrix` vector of matrices containing a measure of similarity between each pair of images (the Hamming distance).
- Use `identify_matches` on a `matchr_matrix` vector to identify pairs of images which are likely to be the same.
- Use `confirm_matches` on the result data frame produced by `identify_matches` to load an interactive Shiny app for visually confirming ambiguous match candidates.
- Use `integrate_changes` to add the results of the visual confirmation to the result data frame.

## Loading images

The first step in a matchr workflow is importing images, either directly as `matchr_image` vectors which contain arrays of pixel values, or indirectly en route to generating the `matchr_signature` image signature vectors used for subsequent steps. matchr can import bitmapped images in the JPEG, PNG, TIFF, and BMP file formats. Images can be identified in two ways:

- As a character vector of URLs or local file paths
- As a length-one character vector containing the path to a local directory containing images

For small image sets such as `example_urls`, we can read the images directly into memory using `load_image`. 

```{r load_image}
img <- load_image(example_urls)
```

```{r load_image_edit, echo = FALSE}
get_path(img) <- display_urls
```

This will create a `matchr_image` vector, each element of which is an array of pixel values. Invalid file paths will produce `NA` values, which will be passed through subsequent matchr functions without "infecting" other results. (I.e., unlike `sum`, which will return `NA` if any inputs are `NA`, matchr functions will ignore `NA` inputs during processing while reporting on the presence of `NA` elements in a fashion appropriate for the given function.) The print method for `matchr_image` vectors displays the resolution, colour profile, and file path of each image.

```{r img}
img
```

One reason to load entire images into memory with `load_image` rather than to just generate image signatures directly from the file paths with `create_signature` is to be able to conveniently see the images themselves. By default, the `plot` method for `matchr_image` vectors will display the first 12 non-NA images in the vector in a grid, along with their file names. Here we set the `max_plot` argument to 15 to show all the non-NA images in the vector.

```{r plot_img, fig.height = 7, fig.width = 7}
plot(img, max_plot = 15)
```

Since the `matchr_image` vectors contain raw arrays of pixel values, it is also possible to apply linear transformations directly to the arrays:

```{r transform_img, fig.height = 6, fig.width = 7}
img_cube <- img[c(1, 5)]
img_root <- img[c(1, 5)]
# Get or set values "inside" matchr vectors with the get_* functions
get_array(img_cube) <- lapply(get_array(img_cube), \(x) x ^ 3)
get_path(img_cube) <- c("img_1 cube", "img_3 cube")
get_array(img_root) <- lapply(get_array(img_root), sqrt)
get_path(img_root) <- c("img_1 root", "img_3 root")
plot(c(img[c(1, 5)], img_cube, img_root))
```

In standard matchr workflows which involve comparing large sets of images, it will rarely be feasible to use `load_image`, given the enormous size of the pixel arrays in memory. (See [the performance vignette](performance.html) for more information.) Instead, `create_signature` can process image sets in batches, reading a small number of images into memory at a time, identifying their distinctive image signatures, and then allowing them to be released from memory before beginning the next batch. This allows arbitrarily large sets of images to be processed by matchr on even relatively modest hardware.

## Creating signatures

The workhorse data structure in matchr is the `matchr_signature` vector of distinctive image signatures calculated from a set of images. These signatures are created using the `create_signature` function, which has methods both for `matchr_image` vectors imported with `load_image` and for a character vector of file paths, which will be sent in batches through a `load_image`-`create_signature` process designed to keep total memory requirements low. Since we already imported a vector of images in the previous section, we can pass this vector as an input to `create_signature`:

```{r create_signature_image}
sig <- create_signature(img)
sig
```

`matchr_signature` vectors print as a string of hexadecimal characters alongside some metadata. These characters represent the values of two 64-bit "perceptual hashes", which can identify images with a high degree of accuracy even in the face of small changes. (See [the matching vignette](matching.html) for more information.) The individual bits of the hashes can be accessed with `get_hash`:

```{r get_signature}
get_hash(sig[1])
```

Using the `plot` method for `matchr_signature` vectors, the signatures can be visualized as follows:

```{r col_img, fig.height = 6, fig.width = 7}
plot(sig)
```

The plot reveals strong similarities between, e.g., the three "img_1" signatures—all of which are in fact taken from variants of the same image.

### Removing black bars

A relatively common phenomenon with user-uploaded photographs is horizontal black bars above and below an image. These occur when users take a screenshot of a landscape-oriented photograph and upload the result. The `example_urls` image set contains one such image:

```{r rm_black_bars_1, fig.height = 6, fig.width = 7}
plot(img[13])
```

These images pose a difficulty for matchr's image signature strategy, because they lead to signatures dominated by black values. Because matchr was motivated by the need to compare large numbers of user-uploaded photographs across different web services, it has the ability to detect and remove horizontal black bars, using the `remove_black_bars` function or the `rm_black_bars` argument to `create_signature`, which is TRUE by default. `remove_black_bars` takes a matchr_image vector, detects and removes black bars, and returns an updated vector:

```{r rm_black_bars_2, fig.height = 6, fig.width = 7}
bb_img <- remove_black_bars(img[13])
get_path(bb_img)[[1]] <- "Black bars removed"
plot(c(img[13], bb_img))
```

When `create_signature` is called with `rm_black_bars = TRUE`, image signatures are only generated from the portion of images which do not have rows of entirely black pixels:

```{r rm_black_bars_3, fig.height = 4, fig.width = 7}
bb_sig <- create_signature(img[13], rm_black_bars = FALSE)
get_path(bb_sig)[[1]] <- "Black bars not removed"
plot(c(bb_sig, sig[13]))
```

## Matching signatures

Once image signatures have been generated, they can be compared to each other using Hamming distances, which use the bit-wise distance between signatures to assess the likelihood that the underlying images are the same. This measurement is carried out with `match_signatures`, which can take either one or two `matchr_signature` vectors as inputs. If you supply a single input, `match_signatures` will identify all potential pairwise matches within that vector If you supply two inputs, `match_signatures` will identify all potential pairwise matches *between* the two vectors. The following examples demonstrate the one-input mode of the function:

```{r match_signatures}
matches <- match_signatures(sig)
matches
```

The output of `match_signatures` is a `matchr_matrix` vector, each element of which is a matrix whose values give a measure of similarity between two of the input image signatures. By default, image signatures are segmented into groups with similar aspect ratios; this is discussed below.




```{r match_signatures_plot}
matches_all <- match_signatures(sig, compare_ar = FALSE)
matches_all |> 
  get_array() |> 
  {\(x) x[[1]]}() |> 
  dplyr::as_tibble() |> 
  setNames(paste0("y_", 1:13)) |> 
  dplyr::mutate(x_id = paste0("x_", dplyr::row_number()), .before = y_1) |> 
  tidyr::pivot_longer(-x_id, names_to = "y_id", values_to = "distance") |> 
  ggplot2::ggplot(ggplot2::aes(x_id, y_id, colour = distance)) +
  ggplot2::geom_point() +
  ggplot2::scale_colour_viridis_c() +
  ggplot2::theme_minimal()
```

The output



```{r match_scatterplot, fig.height = 4, fig.width = 7}
library(ggplot2)

sig_1 <- get_hash(sig)[[1]][1:40] 
sig_2 <- get_hash(sig)[[2]][1:40]
sig_5 <- get_hash(sig)[[5]][1:40]

data.frame(
  x = c(sig_1, sig_1),
  y = c(sig_2, sig_5),
  correlation = c(rep(cor(sig_1, sig_2), 40), rep(cor(sig_1, sig_5), 40))) |> 
  ggplot(aes(x, y)) + 
  geom_point() +
  facet_wrap(vars(correlation)) +
  theme_minimal()
```




### Aspect ratios

By default, image signatures are segmented into groups with similar aspect ratios. This is usually desirable, firstly because images with very different aspect ratios are unlikely to be the same, so segmenting by aspect ratio reduces the chance of false positives. Secondly, splitting by aspect ratios can dramatically reduce the computation time required to match signatures. The printed output from `matches` shows that, of the fifteen image signatures in `img`, two were skipped because they were NA, and then the remaining thirteen were grouped into a 4x4 block, an 8x8 block, and a 1x1 block. In total, this means that 81 comparisons had to be made. If the images weren't split by aspect ratios, it would be necessary to make 13 x 13 = 169 comparisons—more than twice as many.

Splitting by aspect ratios happens using a deterministic version of k-means clustering, with k values between 3 and 8 assessed to identify one that will maximize between-group distance and minimize computational time. In order to avoid any problems with aspect ratios very near a threshold value, the `y` image signatures are split into groups somewhat lower than the lower-bound aspect ratio for a group and somewhat higher than the upper-bound aspect ratio. The `stretch` argument to `match_signatures` controls this parameter. Increasing this value will possibly catch matches between extremely distorted images, but at the cost of potentially larger numbers of false positives, and substantially increased processing time.

If you know that the images you are trying to match may contain significantly distorted aspect ratios, you can set `compare_ar = FALSE` to match all image signatures together:

```{r match_signatures_no_ar}
matches_no_ar <- match_signatures(sig, compare_ar = FALSE)
matches_no_ar
```






## Identifying matches

TKTK


## Manually verifying matches

TKTK


## Helper functions

- get_* functions
- download_images


## Further reading

- [`vignette("matching")`](matching.html) discusses how matchr uses perceptual hashing and Hamming distances to compare images and identify mataches.
- [`vignette("performance")`](performance.html) discusses important performance considerations when using matchr functions on large image sets.

```{r clean_up, echo = FALSE}
match_images <- matchr::match_images
load_image <- matchr::load_image
```
